
# Cat vs Dog Classifier using TensorFlow

This project demonstrates how to clean a dataset, load images, normalize data, build a Convolutional Neural Network (CNN), train the model, and visualize predictions using TensorFlow.

---

##  Step 1: Import Required Libraries

```python
import tensorflow as tf
import matplotlib.pyplot as plt
import os
import shutil
import warnings
import logging
from PIL import ImageFile

1.tensorflow: Main ML library for building the CNN.

2.matplotlib.pyplot: Used to visualize predictions.

3.os, shutil: Help with directory and file handling.

4.warnings, logging: Suppress unnecessary logs.

5.PIL.ImageFile: Allows us to load and validate images
```

## Suppress TensorFlow Warnings

```python
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings('ignore')
tf.get_logger().setLevel(logging.ERROR)
ImageFile.LOAD_TRUNCATED_IMAGES = True
```
## Prevent clutter in output by hiding warnings and logs.
```python
LOAD_TRUNCATED_IMAGES = True:

# TRUNCATED_IMAGES refers to images that are incomplete or not fully loaded
# Avoids crash if an image is incomplete or corrupted.
```

```python
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
```
#This line tells TensorFlow to suppress logging from its C++ backend.
```
Log levels:

'0': Show all logs (default)

'1': Filter out INFO messages

'2': Filter out INFO and WARNING messages

'3': Show only ERROR messages

By setting it to '3', only critical error messages will be printed, reducing output clutter during program execution.
```

```python
warnings.filterwarnings('ignore')

# This line suppresses all warnings generated by Python, including DeprecationWarning, UserWarning, and others.

# This is useful when you want a cleaner console output and are aware that the warnings are not relevant to your current task.


tf.get_logger().setLevel(logging.ERROR)

 # TensorFlow has its own logging system at the Python level. This line sets the TensorFlow logger to only display error messages.

 # This further reduces console clutter by hiding TensorFlow's info and warning messages during model loading, training, or evaluation.


ImageFile.LOAD_TRUNCATED_IMAGES = True

 # This is part of the Pillow (PIL) library. Some images may be partially downloaded or slightly corrupted.

# Setting this to True allows such images to be loaded instead of raising an error, which is especially helpful when working with large datasets where a few images may be damaged.
```

## STEP 1: Clean corrupt images

```python
src_dir = 'Source directory/File name'
clean_dir = 'filtered images will be copied to'
```
# Explanation
```python
if not os.path.exists(clean_dir):
    os.makedirs(clean_dir)
```
What this does:
We check if the folder clean_dir exists on your computer. If it doesn't, we create it.
This folder will hold all the clean, non-corrupted images we're about to copy.

```python

for class_name in os.listdir(src_dir):
```
We go into the main folder where your images are stored (src_dir), and look at every item inside it.
Each item is expected to be a subfolder, like Cat, Dog, etc.

```python

    class_path = os.path.join(src_dir, class_name)
```
We create the full path to that subfolder. For example, if class_name is Cat, then class_path becomes something like /Users/.../Images/Cat.

```python

    if os.path.isdir(class_path):
```
We check if the current item is actually a folder (not a file).
Only folders are useful here, because they contain the image files.

```python
        clean_class_path = os.path.join(clean_dir, class_name)
```
We prepare the matching folder in the clean_dir — for example, /Users/.../Images_clean/Cat.

```python

        os.makedirs(clean_class_path, exist_ok=True)
```
We create that matching folder. If it already exists, we skip creating it (no error happens because of exist_ok=True).

```python

        for file in os.listdir(class_path):
```
Now we go inside the class folder (like Cat) and look at every file inside it.

```python

            if file.lower().endswith(('.jpg/.JPG/.Jpg')):
```
We check if the file is a .jpg image.
We use .lower() so it catches .JPG, .jpg, .Jpg, etc.

```python

                src_path = os.path.join(class_path, file)
                dst_path = os.path.join(clean_class_path, file)
```
We build the full path to where the image currently is (src_path) and where we want to copy it if it’s valid (dst_path).

```python

                try:
```
We now try to read and test if the image is okay.

```python

                    img_bytes = tf.io.read_file(src_path)
```
We read the image file as raw bytes — like saying, “grab the contents of the file.”

```python

                    img = tf.image.decode_image(img_bytes)
```
We try to decode the image — basically, TensorFlow tries to understand the format (JPG/PNG) and make sure it's a real image.

```python
                img.numpy()
```
This line forces the decoding to happen right away (because TensorFlow can delay operations otherwise).
If the image is corrupt, this is the line that would crash — unless we catch the error.

```python

                    shutil.copy2(src_path, dst_path)
```
If everything worked fine and the image is clean, we copy it to the new clean folder.

```python

                except:
                    pass
```
If anything goes wrong (the image is broken, unreadable, etc.), we just skip it and move on.
We don’t print an error or stop the program — we quietly ignore the bad file.

## STEP 2: Load and Normalize Dataset 
```
print(" Loading dataset...")
```
This prints a message to let you know that the image loading process is starting.

```python
train_ds = tf.keras.utils.image_dataset_from_directory(
    clean_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(150, 150),
    batch_size=32
)
```
```
What this does:
Loads the cleaned images from the clean_dir folder.

Splits 20% of the data for validation, and uses the remaining 80% for training.

subset="training": This part loads the training portion.

seed=123: Ensures the split is reproducible every time you run the code.

image_size=(150, 150): Resizes all images to 150x150 pixels.

batch_size=32: Loads 32 images at a time during training.
```

```python

val_ds = tf.keras.utils.image_dataset_from_directory(
    clean_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(150, 150),
    batch_size=32
)
```
Same as above, but:

This loads the validation set (the 20% portion).

Same directory, same seed, same image size, and batch size.

```python
class_names = train_ds.class_names
```
This line stores the names of the classes (e.g., ["Cat", "Dog"]) based on the subfolder names inside clean_dir.




