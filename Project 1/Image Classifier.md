
# Cat vs Dog image Classifier using TensorFlow

This project demonstrates how to clean a dataset, load images, normalize data, build a Convolutional Neural Network (CNN), train the model, and visualize predictions using TensorFlow.

---

##  Step 1: Import Required Libraries

```python
import tensorflow as tf
import matplotlib.pyplot as plt
import os
import shutil
import warnings
import logging
from PIL import ImageFile

1.tensorflow: Main ML library for building the CNN.

2.matplotlib.pyplot: Used to visualize predictions.

3.os, shutil: Help with directory and file handling.

4.warnings, logging: Suppress unnecessary logs.

5.PIL.ImageFile: Allows us to load and validate images
```

## Suppress TensorFlow Warnings

```python
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings('ignore')
tf.get_logger().setLevel(logging.ERROR)
ImageFile.LOAD_TRUNCATED_IMAGES = True
```
## Prevent clutter in output by hiding warnings and logs.
```python
LOAD_TRUNCATED_IMAGES = True:

# TRUNCATED_IMAGES refers to images that are incomplete or not fully loaded
# Avoids crash if an image is incomplete or corrupted.
```

```python
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
```
#This line tells TensorFlow to suppress logging from its C++ backend.
```
Log levels:

'0': Show all logs (default)

'1': Filter out INFO messages

'2': Filter out INFO and WARNING messages

'3': Show only ERROR messages

By setting it to '3', only critical error messages will be printed, reducing output clutter during program execution.
```

```python
warnings.filterwarnings('ignore')

# This line suppresses all warnings generated by Python, including DeprecationWarning, UserWarning, and others.

# This is useful when you want a cleaner console output and are aware that the warnings are not relevant to your current task.


tf.get_logger().setLevel(logging.ERROR)

 # TensorFlow has its own logging system at the Python level. This line sets the TensorFlow logger to only display error messages.

 # This further reduces console clutter by hiding TensorFlow's info and warning messages during model loading, training, or evaluation.


ImageFile.LOAD_TRUNCATED_IMAGES = True

 # This is part of the Pillow (PIL) library. Some images may be partially downloaded or slightly corrupted.

# Setting this to True allows such images to be loaded instead of raising an error, which is especially helpful when working with large datasets where a few images may be damaged.
```

## STEP 2: Clean corrupt images

```python
src_dir = 'Source directory/File name'
clean_dir = 'filtered images will be copied to'
```
# Explanation
```python
if not os.path.exists(clean_dir):
    os.makedirs(clean_dir)
```
What this does:
We check if the folder clean_dir exists on your computer. If it doesn't, we create it.
This folder will hold all the clean, non-corrupted images we're about to copy.

```python

for class_name in os.listdir(src_dir):
```
We go into the main folder where your images are stored (src_dir), and look at every item inside it.
Each item is expected to be a subfolder, like Cat, Dog, etc.

```python

    class_path = os.path.join(src_dir, class_name)
```
We create the full path to that subfolder. For example, if class_name is Cat, then class_path becomes something like /Users/.../Images/Cat.

```python

    if os.path.isdir(class_path):
```
We check if the current item is actually a folder (not a file).
Only folders are useful here, because they contain the image files.

```python
        clean_class_path = os.path.join(clean_dir, class_name)
```
We prepare the matching folder in the clean_dir — for example, /Users/.../Images_clean/Cat.

```python

        os.makedirs(clean_class_path, exist_ok=True)
```
We create that matching folder. If it already exists, we skip creating it (no error happens because of exist_ok=True).

```python

        for file in os.listdir(class_path):
```
Now we go inside the class folder (like Cat) and look at every file inside it.

```python

            if file.lower().endswith(('.jpg/.JPG/.Jpg')):
```
We check if the file is a .jpg image.
We use .lower() so it catches .JPG, .jpg, .Jpg, etc.

```python

                src_path = os.path.join(class_path, file)
                dst_path = os.path.join(clean_class_path, file)
```
We build the full path to where the image currently is (src_path) and where we want to copy it if it’s valid (dst_path).

```python

                try:
```
We now try to read and test if the image is okay.

```python

                    img_bytes = tf.io.read_file(src_path)
```
We read the image file as raw bytes — like saying, “grab the contents of the file.”

```python

                    img = tf.image.decode_image(img_bytes)
```
We try to decode the image — basically, TensorFlow tries to understand the format (JPG/PNG) and make sure it's a real image.

```python
                img.numpy()
```
This line forces the decoding to happen right away (because TensorFlow can delay operations otherwise).
If the image is corrupt, this is the line that would crash — unless we catch the error.

```python

                    shutil.copy2(src_path, dst_path)
```
If everything worked fine and the image is clean, we copy it to the new clean folder.

```python

                except:
                    pass
```
If anything goes wrong (the image is broken, unreadable, etc.), we just skip it and move on.
We don’t print an error or stop the program — we quietly ignore the bad file.

## STEP 3: Load and Normalize Dataset 
```
print(" Loading dataset...")
```
This prints a message to let you know that the image loading process is starting.

```python
train_ds = tf.keras.utils.image_dataset_from_directory(
    clean_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(150, 150),
    batch_size=32
)

What this does:
Loads the cleaned images from the clean_dir folder.

Splits 20% of the data for validation, and uses the remaining 80% for training.

subset="training": This part loads the training portion.

seed=123: Ensures the split is reproducible every time you run the code.

image_size=(150, 150): Resizes all images to 150x150 pixels.

batch_size=32: Loads 32 images at a time during training.
```

```python

val_ds = tf.keras.utils.image_dataset_from_directory(
    clean_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(150, 150),
    batch_size=32
)

Same as above, but:

This loads the validation set (the 20% portion).

Same directory, same seed, same image size, and batch size.
```

```python
class_names = train_ds.class_names
```
This line stores the names of the classes (e.g., ["Cat", "Dog"]) based on the subfolder names inside clean_dir.

## Normalize Images

Normalization is the process of scaling data (such as image pixel values or numerical features) to a standard range, often between 0 and 1 or -1 and 1.


```python
normalization_layer = tf.keras.layers.Rescaling(1./255)

What this does:
Creates a normalization layer that rescales pixel values.

Original pixel values are in the range [0, 255] (typical for images).

1./255 converts them to [0, 1], which is better for training neural networks.

Helps models train faster and more accurately.
```

```python
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))

Applies the normalization layer to every image in the training dataset.

x is the image, y is the label.

The map function modifies each (image, label) pair in the dataset.

Output: same dataset structure, but with rescaled pixel values.
```

```python

val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))

Same thing, but applied to the validation dataset.
Ensures both training and validation images are on the same scale.
```

## Prefetch for performance

Prefetching is a technique that allows the system to prepare the next batch of data while the current batch is being processed by the model.

```python
AUTOTUNE = tf.data.AUTOTUNE

What it does:
AUTOTUNE is a TensorFlow setting that lets the system automatically determine the optimal prefetch buffer size.
It’s used to make data loading and preprocessing more efficient, especially during training.
```

```python
train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
What this does:

.cache(): => Stores the dataset in memory after the first epoch.

So in the next epoch, it doesn't have to read from disk again.

.prefetch(): => Starts preparing the next batch of data while the current batch is being used by the model.

This overlaps data preprocessing and model execution to reduce training latency.
```

```python
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
Does the same caching and prefetching for the validation dataset.
```

## Build the CNN Model

```python

ReLU (Rectified Linear Unit) is an activation function defined as:
f(x) = max(0, x)
If the input is positive, ReLU returns the input itself.

The Sigmoid function is an S-shaped curve defined as:
f(x) = 1 / (1 + e^(-x))
This transforms any input into a value between 0 and 1.
If the input is zero or negative, ReLU returns 0.

model = tf.keras.Sequential([
This line creates a Sequential model, meaning the layers are added one after another in order.

tf.keras.layers.Input(shape=(150, 150, 3)),
Defines the input shape of the model:
150x150 pixels (height and width)
3 channels (for RGB images)

tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
This is the first convolutional layer:
Applies 32 filters of size 3x3 to the input image
Detects small patterns like edges and textures
Uses ReLU activation to introduce non-linearity

tf.keras.layers.MaxPooling2D(2, 2),
This is a max pooling layer:
Reduces the size of the feature maps by taking the max value in each 2x2 block
Helps reduce computation and extract dominant features

tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
tf.keras.layers.MaxPooling2D(2, 2),
Adds a second convolutional layer with 64 filters, followed by another pooling layer.
These help the model detect more complex features.

tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
tf.keras.layers.MaxPooling2D(2, 2),
Third convolutional layer with 128 filters. This layer helps the model learn even deeper features like shapes and structures. Again followed by pooling.

tf.keras.layers.Flatten(),
Flattens the output from the previous layers into a 1D vector so it can be fed into a dense (fully connected) layer.

tf.keras.layers.Dense(128, activation='relu'),
A fully connected layer with 128 neurons and ReLU activation. This layer helps the model learn complex patterns from the flattened features.

tf.keras.layers.Dense(1, activation='sigmoid')])
The final output layer:
Only 1 neuron with a sigmoid activation
Outputs a value between 0 and 1
Perfect for binary classification (e.g., Cat vs Dog)
```


